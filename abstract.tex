This work proposes a system capable of estimating the longitudinal velocity of
a wheeled robot on loose sandy terrain using only acoustic sensors. These will
likely be present anyway in many future ground mobile robots for human-robot
interaction purposes. The proposed system consists of an audio feature
extraction module, based on gammatone filterbanks, and a prediction module,
based on a convolutional neural network. The proposed system has been tested in
a single wheel test bed with a wheel driving up to speeds of 0.07 m/s with a
wide range of wheel slippage resulting in an average drift of 5 mm/s. A
qualitative evaluation of the proposed system against other sources of odometry
shows that acoustic and visual methods vulnerabilities do not overlap, which
indicates that a system based on acoustic sensors can be a feasible auxiliary
source of odometry. The system is able to make a prediction from a single audio
frame with a duration of 15ms in only 2ms on a user-level commercially
available CPU. Additional experiments with white Gaussian noise show that high
noise power (Signal to Noise Ratio of -10 dB) only affects significantly the
prediction of speeds close to 0ms.