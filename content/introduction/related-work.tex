\subsection{Related work} \label{sec:related-work}

\nameref{para:audio-based-odometry} is a relatively unexplored field, but robot
audition is present in self-localization and navigating tasks using
\nameref{para:sound-source-localization}, where the robot's ego-noise is
usually seen as a nuisance. 

% Review35: the authors mention that a similar work by L Marchegiani and P
% Newman using ego-noise to regress velocity and angular velocity are limited
% in experiments and evaluation, but these limitations aren't substantiated.

\paragraph{Audio-based Odometry} \label{para:audio-based-odometry} In
\cite{HowDoISoundLike}, the authors propose a classification framework to
associate ego-noise captured with an onboard microphone to a set of predefined
velocity profiles. Additionally, they are able to detect a change in the
inclination of the surface the robot is moving. However, the application of
this framework is rather limited. On the other hand, \cite{marchegiani2018a}
proposes a system capable of estimating ground robots' linear and angular
velocities using onboard audio sensors. It uses deep neural networks to regress
the motion of a vehicle from feature representations (based on Gammatone
filterbanks) of the sensed audio. The authors conclude that audio-based
odometry systems should be useful auxiliary sources of odometry on the side of
more traditional systems. However, their evaluation is limited to a single
experiment which is randomly split in a training and test dataset, without a
validation split and they do not evaluate the computational cost of their
solution.

\paragraph{Sound Source localization} \label{para:sound-source-localization} In
\cite{AcousticSLAM} and \cite{SoundSourceMapping}, the authors propose an
algorithm to simultaneously localize a robot and map its environment (SLAM)
using onboard audio sensors that perceive sound sources in its environment.
Alternatively, \cite{Allen2012} perceives the robot's intrinsic noise to
localize it using external audio sensors. Combinations with other
self-localization methods are proposed in \cite{AcousticFusion}, where onboard
sound sensors identify and remove the effect of dynamic obstacles for Visual
SLAM, and \cite{Gautam2014}, which localizes sounds using onboard microphones
and uses them as navigation goals while using Visual SLAM for
self-localization.

% ICRA23 REVIEW29: In related work, terrain classification seems not relevant
% to the main topic of this paper.

% RoMoCo24 REVIEW271: The presented paper can be viewed more as a proof of
% concept than mature research. The idea is not as innovative as the authors
% even mentioned it. They showed similar approaches and also failed to cite one
% of the early approaches to terrain classification on wheeled robots with a
% microphone: Valada2018 and DeepTerrain (This review is contradictory with the
% ICRA23 REVIEW29, citations where there and it is difficult to fit them in the
% 6 page limit).

% \paragraph{Terrain Classification} \label{para:terrain-classification} Multiple
% works propose to identify the terrain type of a robot's environment using
% onboard audio sensors. \cite{Valada2018} proposes a deep learning framework,
% based on a convolutional neural network, that uses only sound from
% vehicle-terrain interactions to classify a wide range of indoor and outdoor
% terrains. This method is extended in \cite{DeepTerrain}, where an unsupervised
% classifier that learns from vehicle-terrain interaction sounds supervises a
% pixel-wise semantic image classifier. Similarly, \cite{Kurobe2021} proposes a
% multi-modal self-supervised learning technique that switches between audio and
% image features to cluster terrain types. Extended as well by
% \cite{Ishikawa2021} using a multi-modal variational autoencoder and a Gaussian
% mixture model clustering algorithm on audio-visual data. It proposes as well to
% use gammatone-based filtering methods to extract audio features like in
% \cite{marchegiani2018a}.
